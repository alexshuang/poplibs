// Copyright (c) 2018 Graphcore Ltd. All rights reserved.
#define BOOST_TEST_MODULE ScaledAddSupervisor_fp
#include "poplibs_test/Util.hpp"
#include "popops/codelets.hpp"
#include <poplar/Engine.hpp>
#include <poplibs_support/TestDevice.hpp>
#include <poputil/TileMapping.hpp>

using namespace poplar;
using namespace poplar::program;
using namespace poplibs_test::util;
using namespace poplar_test;
using namespace poplibs_support;

#define N 80

// Test data, generated by:
// python -c "import random; print [round(random.uniform(0, 100), 4)
//    for _ in range(N)]"

const float data[N] = {
    0.8534,  2.9833,  38.2024, 87.3113, 8.3774,  27.5261, 97.3378, 63.7722,
    52.5539, 30.8552, 78.9132, 11.1624, 61.1376, 42.0059, 20.9077, 10.4159,
    47.8163, 10.6081, 19.2055, 48.1933, 42.9815, 73.1804, 65.6732, 56.2054,
    83.5201, 54.353,  27.3245, 6.1426,  84.6202, 59.0347, 52.5354, 0.3793,
    65.2122, 18.2263, 32.5403, 13.1368, 65.8324, 97.6239, 31.3668, 26.183,
    16.7465, 88.9421, 82.422,  31.6807, 89.8731, 64.4955, 59.5105, 18.8455,
    62.2198, 7.2624,  24.9691, 15.5876, 79.9009, 20.5059, 13.2128, 38.238,
    76.9248, 99.4896, 15.4235, 89.3595, 71.5428, 62.7379, 45.6806, 6.0773,
    81.0174, 33.8174, 1.0395,  57.2691, 67.4487, 78.0565, 60.1302, 39.5229,
    39.6528, 37.9882, 45.9843, 50.885,  37.9814, 26.9937, 0.727,   89.451};

const float deltas[N] = {
    5.8678,  87.3042, 27.6216, 61.4568, 65.8711, 93.0195, 34.1048, 74.3848,
    36.9936, 48.9242, 80.4252, 82.9536, 8.6372,  96.0092, 41.1759, 86.8282,
    52.3811, 76.1267, 27.2576, 19.4517, 17.4603, 84.3021, 98.6319, 48.2396,
    90.1868, 28.2355, 62.9416, 93.7382, 74.413,  7.4225,  48.916,  96.0203,
    98.1374, 33.2734, 94.4999, 38.9091, 31.4119, 42.8233, 43.049,  82.7856,
    56.9155, 5.2595,  65.9839, 1.8433,  58.3097, 41.7467, 43.9233, 33.41,
    81.7994, 87.5566, 63.5808, 57.3755, 9.3762,  78.467,  84.4506, 89.7413,
    18.6427, 45.7754, 7.3802,  8.0999,  73.7112, 42.8081, 15.3092, 63.5193,
    3.4319,  48.2729, 71.1376, 47.277,  7.7794,  77.9405, 89.8753, 70.6456,
    24.8513, 70.6801, 17.3198, 55.721,  41.1727, 33.0615, 0.3736,  49.9985};

double atol(const Type &type) { return type == HALF ? 1e-7 : 1e-20; }

const float k = 0.8424;

void testScaledAddSupervisor(
    const char *vertex, const Type &dataType, const Type &deltaType,
    const Type &scaleType, const bool &constantFactor, const float &factorA,
    const float &factorB, const float &factorData = 1.0,
    const float &factorDelta = 1.0, const float testSign = 1.0,
    const bool doXminusaXPlusbY = false, const float &scaleFloatTolerance = 0.0,
    const double testTolerance = 0.1) {
  auto device = createTestDevice(TEST_TARGET, 1, 4);
  auto &target = device.getTarget();
  Graph graph(device.getTarget());
  float scaledData[N];
  float scaledDeltas[N];

  popops::addCodelets(graph);

  // Scale the input vectors
  for (unsigned i = 0; i < N; i++) {
    scaledData[i] = factorData * data[i];
    scaledDeltas[i] = factorDelta * deltas[i];
  }
  const bool vertexHasTolerance =
      (std::string(vertex).rfind("popops::ScaledAddSupervisor", 0) == 0 ||
       std::string(vertex).rfind("popops::aXPlusbYSupervisor", 0) == 0) &&
      dataType == HALF && deltaType == HALF && scaleType == FLOAT;
  Sequence prog;

  auto dataTensor = graph.addVariable(dataType, {N});
  poputil::mapTensorLinearly(graph, dataTensor);

  graph.createHostWrite("data", dataTensor);

  auto deltasTensor = graph.addVariable(deltaType, {N});
  poputil::mapTensorLinearly(graph, deltasTensor);
  graph.createHostWrite("deltas", deltasTensor);

  std::vector<Tensor> outs;
  outs.reserve(N);

  // put a test case on each tile.
  // We test each length from 1 to N
  auto cs = graph.addComputeSet("cs");
  for (unsigned i = 1; i <= N; ++i) {
    const unsigned tile = (i - 1) % target.getTilesPerIPU();

    auto v = graph.addVertex(cs, vertex);
    graph.setTileMapping(v, tile);

    Interval interval = {0, i};
    auto A = graph.addVariable(dataType, {N});
    graph.setTileMapping(A, tile);

    prog.add(Copy(dataTensor, A));
    outs.push_back(A);

    graph.connect(v["A"], A.slice(interval));
    graph.connect(v["B"], deltasTensor.slice(interval));

    graph.setInitialValue(v["size"], i);

    if (constantFactor) {
      if (factorA == 1.0) {
        graph.setInitialValue(v["scaleB"], std::fabs(factorB));
      } else {
        graph.setInitialValue(v["scaleA"], factorA);
        graph.setInitialValue(v["scaleB"], factorB);
      }
    } else {
      auto factorBTensor = graph.addVariable(scaleType, {});
      graph.setTileMapping(factorBTensor, tile);
      if (factorA == 1.0) {
        graph.connect(v["scaleB"], factorBTensor.reshape({1}));
        graph.setInitialValue(factorBTensor, std::fabs(factorB));
      } else {
        graph.connect(v["scaleB"], factorBTensor.reshape({1}));
        graph.setInitialValue(factorBTensor, factorB);

        auto factorATensor = graph.addVariable(scaleType, {});
        graph.setTileMapping(factorATensor, tile);
        graph.connect(v["scaleA"], factorATensor.reshape({1}));
        graph.setInitialValue(factorATensor, factorA);
      }
      if (vertexHasTolerance) {
        // Chosen to force us to test the half,half,float vertex variant
        graph.setInitialValue(v["tolerance"], scaleFloatTolerance);
      }
    }
  }
  prog.add(Execute(cs));

  auto out = concat(outs);
  graph.createHostRead("out", out);

  std::vector<char> dataBuffer(N * target.getTypeSize(dataType));
  std::vector<char> deltaBuffer(N * target.getTypeSize(deltaType));
  copy(target, scaledData, N, dataType, dataBuffer.data());
  copy(target, scaledDeltas, N, deltaType, deltaBuffer.data());

  // one tensor for each slice {0..N}
  std::vector<char> outBuffer(N * N * target.getTypeSize(dataType));

  Engine e(graph, prog);
  device.bind([&](const Device &d) {
    e.load(d);

    e.writeTensor("data", dataBuffer.data(),
                  dataBuffer.data() + dataBuffer.size());
    e.writeTensor("deltas", deltaBuffer.data(),
                  deltaBuffer.data() + deltaBuffer.size());

    e.run();

    e.readTensor("out", outBuffer.data(), outBuffer.data() + outBuffer.size());
  });

  std::array<float, N> expected;
  std::array<float, N> actual;
  std::copy(&scaledData[0], &scaledData[N], std::begin(expected));

  for (unsigned i = 0; i < N; ++i) {
    const auto start = i * N * target.getTypeSize(dataType);
    copy(target, dataType, outBuffer.data() + start, actual.data(), N);

    auto dataScaling = doXminusaXPlusbY ? 1 - factorA : factorA;
    // Generate the next required result given the length of the test has
    // increased by one. Earlier expected results have already been computed.
    // Later expected results remain equal to the original input value until
    // overwritten.
    expected[i] =
        dataScaling * scaledData[i] + testSign * factorB * scaledDeltas[i];
    auto test = "n=" + std::to_string(i);
    BOOST_CHECK(checkIsClose(test, actual.data(), {N}, expected.data(), N,
                             testTolerance, atol(dataType)));
  }
}

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorFloatHalfHalf)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorFloatHalfHalf) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<float,half,half,false,false>", FLOAT, HALF,
      HALF, false, 1.0, k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorFloatHalfFloat)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorFloatHalfFloat) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<float,half,float,false,false>", FLOAT, HALF,
      FLOAT, false, 1.0, k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorHalfHalfFloatTensorHighTol)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorHalfHalfFloatTensorHighTol) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,float,false,true>", HALF, HALF,
      FLOAT, false, 1.0, k, 1.0, 1.0, 1.0, false, 1e-3);
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,float,false,false>", HALF, HALF,
      FLOAT, false, 1.0, k, 1.0, 1.0, 1.0, false, 1e-3);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorHalfHalfFloatTensorLowTol)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorHalfHalfFloatTensorLowTol) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,float,false,true>", HALF, HALF,
      FLOAT, false, 1.0, 1e-6, 6e-8, 655.0, 1.0, false, 0.0, 0.01);
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,float,false,false>", HALF, HALF,
      FLOAT, false, 1.0, 1e-6, 6e-8, 655.0, 1.0, false, 0.0, 0.01);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorHalfTensor)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorHalfTensor) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,half,false,true>", HALF, HALF,
      HALF, false, 1.0, k);
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,half,half,false,false>", HALF, HALF,
      HALF, false, 1.0, k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorFloatTensor)

BOOST_AUTO_TEST_CASE(ScaledAddSupervisorFloatTensor) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<float,float,float,false,true>", FLOAT, FLOAT,
      FLOAT, false, 1.0, k);
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<float,float,float,false,false>", FLOAT,
      FLOAT, FLOAT, false, 1.0, k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorHalfFloatHalfTensor)
BOOST_AUTO_TEST_CASE(ScaledAddSupervisorHalfFloatHalfTensor) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,float,half,false,false>", HALF, FLOAT,
      HALF, false, 1.0, k);
}
BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledAddSupervisorHalfFloatFloat)
BOOST_AUTO_TEST_CASE(ScaledAddSupervisorHalfFloatFloatTensor) {
  testScaledAddSupervisor(
      "popops::ScaledAddSupervisor<half,float,float,false,false>", HALF, FLOAT,
      FLOAT, false, 1.0, k);
}
BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledSubtractSupervisorHalfTensor)

BOOST_AUTO_TEST_CASE(ScaledSubtractSupervisorHalfTensor) {
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,half,true>", HALF, HALF, HALF,
      false, 1.0, -k);
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,half,false>", HALF, HALF,
      HALF, false, 1.0, -k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledSubtractSupervisorFloatTensor)

BOOST_AUTO_TEST_CASE(ScaledSubtractSupervisorFloatTensor) {
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<float,float,float,true>", FLOAT, FLOAT,
      FLOAT, false, 1.0, -k);
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<float,float,float,false>", FLOAT, FLOAT,
      FLOAT, false, 1.0, -k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledSubtractSupervisorFloatHalfTensor)

BOOST_AUTO_TEST_CASE(ScaledSubtractSupervisorFloatHalfTensor) {
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,float,half,true>", HALF, FLOAT,
      HALF, false, 1.0, -k);
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,float,half,false>", HALF, FLOAT,
      HALF, false, 1.0, -k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledSubtractSupervisorHalfHalfFloatTensorHighTol)

BOOST_AUTO_TEST_CASE(ScaledSubtractSupervisorHalfHalfFloatTensorHighTol) {
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,float,true>", HALF, HALF,
      FLOAT, false, 1.0, k, 1.0, 1.0, -1.0, false, 1e-3);
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,float,false>", HALF, HALF,
      FLOAT, false, 1.0, k, 1.0, 1.0, -1.0, false, 1e-3);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(ScaledSubtractSupervisorHalfHalfFloatTensorLowTol)

BOOST_AUTO_TEST_CASE(ScaledSubtractSupervisorHalfHalfFloatTensorLowTol) {
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,float,true>", HALF, HALF,
      FLOAT, false, 1.0, 1e-6, 6e-8, 655.0, -1.0, false, 0.0, 0.01);
  testScaledAddSupervisor(
      "popops::ScaledSubtractSupervisor<half,half,float,false>", HALF, HALF,
      FLOAT, false, 1.0, 1e-6, 6e-8, 655.0, -1.0, false, 0.0, 0.01);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(aXPlusbYSupervisorHalfTensor)

BOOST_AUTO_TEST_CASE(aXPlusbYSupervisorHalfTensor) {
  testScaledAddSupervisor("popops::aXPlusbYSupervisor<half,half,false,true>",
                          HALF, HALF, HALF, false, -0.5 * k, k);
  testScaledAddSupervisor("popops::aXPlusbYSupervisor<half,half,false,false>",
                          HALF, HALF, HALF, false, -0.5 * k, k);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(aXPlusbYSupervisorMixedTensor)

BOOST_AUTO_TEST_CASE(aXPlusbYSupervisorMixedTensorSlow) {
  // Run with a small tolerance (0.0001%) so that at runtime we chose the
  // slower mixed (data=HALF, scale values=FLOAT) path
  testScaledAddSupervisor("popops::aXPlusbYSupervisor<half,float,false,false>",
                          HALF, HALF, FLOAT, false, -0.5 * k, k, 1.0, 1.0, 1.0,
                          false, 1e-6);
}
BOOST_AUTO_TEST_CASE(aXPlusbYSupervisorMixedTensorFast) {
  // Run with a big tolerance (1%) so that at runtime we chose the fast
  // path with data=HALF, scale values=HALF
  testScaledAddSupervisor("popops::aXPlusbYSupervisor<half,float,false,false>",
                          HALF, HALF, FLOAT, false, -0.5 * k, k, 1.0, 1.0, 1.0,
                          false, 1e-2);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(XMinusaXPlusbYSupervisorHalfTensor)

BOOST_AUTO_TEST_CASE(XMinusaXPlusbYSupervisorHalfTensor) {
  testScaledAddSupervisor("popops::XMinusaXPlusbYSupervisor<half,false,true>",
                          HALF, HALF, HALF, false, -0.5 * k, k, 1, 1, 1, true);
  testScaledAddSupervisor("popops::XMinusaXPlusbYSupervisor<half,false,false>",
                          HALF, HALF, HALF, false, -0.5 * k, k, 1, 1, 1, true);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(aXMinusbYSupervisorHalfTensor)

BOOST_AUTO_TEST_CASE(aXMinusbYSupervisorHalfTensor) {
  // testSign = -1.0 to test aXMinusb
  testScaledAddSupervisor("popops::aXMinusbYSupervisor<half,half,false,true>",
                          HALF, HALF, HALF, false, -0.5 * k, k, 1.0, 1.0, -1.0);
  testScaledAddSupervisor("popops::aXMinusbYSupervisor<half,half,false,false>",
                          HALF, HALF, HALF, false, -0.5 * k, k, 1.0, 1.0, -1.0);
}

BOOST_AUTO_TEST_SUITE_END()

BOOST_AUTO_TEST_SUITE(aXMinusbYSupervisorMixedTensor)

BOOST_AUTO_TEST_CASE(aXMinusbYSupervisorMixedTensorSlow) {
  // Run with a small tolerance (0.0001%) so that at runtime we chose the
  // slower mixed (data=HALF, scale values=FLOAT) path
  testScaledAddSupervisor("popops::aXMinusbYSupervisor<half,float,false,false>",
                          HALF, HALF, FLOAT, false, -0.5 * k, k, 1.0, 1.0, -1.0,
                          false, 1e-6);
}
BOOST_AUTO_TEST_CASE(aXMinusbYSupervisorMixedTensorFast) {
  // Run with a big tolerance (1%) so that at runtime we chose the fast
  // path with data=HALF, scale values=HALF
  testScaledAddSupervisor("popops::aXMinusbYSupervisor<half,float,false,false>",
                          HALF, HALF, FLOAT, false, -0.5 * k, k, 1.0, 1.0, -1.0,
                          false, 1e-2);
}

BOOST_AUTO_TEST_SUITE_END()
